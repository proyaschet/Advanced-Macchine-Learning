{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Stacked Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): \n",
    "\n",
    "Student Number(s):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "#from TAS_Python_Utilities import data_viz\n",
    "#from TAS_Python_Utilities import data_viz_target\n",
    "#from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to create classifer objects based on a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(classifier_type, tree_min_samples_split = 20):\n",
    "\n",
    "    if classifier_type == \"svm\":\n",
    "        c = svm.SVC(probability=True)\n",
    "\n",
    "    elif classifier_type == \"logreg\":\n",
    "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "\n",
    "    elif classifier_type == \"knn\":\n",
    "        c = neighbors.KNeighborsClassifier()\n",
    "\n",
    "    elif classifier_type == \"tree\":\n",
    "        c = tree.DecisionTreeClassifier(min_samples_split = tree_min_samples_split)\n",
    "\n",
    "    elif classifier_type == \"randomforest\":\n",
    "        c = ensemble.RandomForestClassifier()\n",
    "        \n",
    "    else:\n",
    "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackedEnsembleClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimators: list \n",
    "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
    "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
    "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
    "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
    "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
    "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
    "    classifier_duplicates: int, optional (default = 1)\n",
    "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
    "    stack_layer_classifier: string, optional (default = \"logreg')\n",
    "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
    "    training_folds: int, optional (default = 4)\n",
    "        How many folds will be used to generate the training set for the stacked layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels (single output problem).\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedEnsembleClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator_types: The types of classifiers to include at the base layer\n",
    "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
    "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Nothing\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise class variabels\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"    \n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        ########################\n",
    "        # LEVEL 0\n",
    "        ########################\n",
    "        \n",
    "        # Set up the base classifeirs in the ensemble\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        # Store the number of classifers in the ensemble\n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "\n",
    "        # Use all training data to train base classifiers\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        \n",
    "        # Set up empty arrays to hold stack layer training data\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_train\n",
    "          \n",
    "        # Train each base calssifier and generate the stack layer training dataset\n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract a bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            # Make predictions for all instances in the training set\n",
    "            y_pred = classifier.predict_proba(X_train)\n",
    "\n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "      \n",
    "        ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "   \n",
    "        X_stack_queries = None\n",
    "              \n",
    "        # Make a prediction with each base classifier and assemble the stack layer query\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "        \n",
    "        # Return the prediction made by the stack layer classifier\n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the StackedEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.96      0.98        50\n",
      "          2       0.96      1.00      0.98        50\n",
      "\n",
      "avg / total       0.99      0.99      0.99       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  48   2   50\n",
       "2           0   0  50   50\n",
       "All        50  48  52  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleClassifier()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         0.93333333 0.93333333 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.9666666666666666  +/-  0.033333333333333326\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Design the StackedEnsembleHoldOut Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "class StackedEnsembleClassifierHoldOut(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.classifiers_ = list()\n",
    "        \n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "        \n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "        \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = y_test\n",
    "        \n",
    "        for classifier in self.classifiers_:\n",
    "\n",
    "            # Extract a bootstrap sample\n",
    "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
    "            \n",
    "            # Train a base classifier\n",
    "            classifier.fit(X_train_samp, y_train_samp)\n",
    "            \n",
    "            # Make predictions for all instances in the training set\n",
    "            y_pred = classifier.predict_proba(X_test)\n",
    "\n",
    "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
    "            try:\n",
    "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
    "            except ValueError:\n",
    "                self.X_stack_train = y_pred\n",
    "                \n",
    "        \n",
    "         ########################\n",
    "        # LEVEL 1\n",
    "        ########################\n",
    "        \n",
    "        # Create the stack layer classifier\n",
    "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "\n",
    "        # Train the stack layer using the newly created dataset\n",
    "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "        # Return the classifier\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "        X = check_array(X)\n",
    "        X_stack_queries = None\n",
    "        \n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "                \n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       1.00      0.94      0.97        50\n",
      "          2       0.94      1.00      0.97        50\n",
      "\n",
      "avg / total       0.98      0.98      0.98       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  47   3   50\n",
       "2           0   0  50   50\n",
       "All        50  47  53  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleClassifierHoldOut()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Design the StackedEnsembleKFold Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "class StackedEnsembleClassifierKFold(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\", folds = 3):\n",
    "        self.base_estimator_types = base_estimator_types\n",
    "        self.base_estimator_type_list = list()\n",
    "        self.base_estimator_duplicates = base_estimator_duplicates\n",
    "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
    "        self.folds = folds\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.classifiers_ = list()\n",
    "        for i in range(0, self.base_estimator_duplicates):\n",
    "            for t in self.base_estimator_types:\n",
    "\n",
    "                self.base_estimator_type_list.append(t)      \n",
    "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                self.classifiers_.append(c)\n",
    "                \n",
    "        self.n_estimators_ = len(self.classifiers_)\n",
    "        \n",
    "        kfold = StratifiedKFold(n_splits= self.folds)\n",
    "        self.X_stack_train = None #(dtype = float)\n",
    "        self.y_stack_train = np.array([])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            \n",
    "            self.y_stack_train = np.r_[self.y_stack_train, y_test]\n",
    "            \n",
    "            X_stack_train_fold = None\n",
    "            \n",
    "            for classifier in self.classifiers_:\n",
    "                X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)\n",
    "                \n",
    "                classifier.fit(X_train_samp, y_train_samp)\n",
    "                \n",
    "                y_pred = classifier.predict_proba(X_test)\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    X_stack_train_fold = np.c_[X_stack_train_fold, y_pred]\n",
    "                except ValueError:\n",
    "                    X_stack_train_fold = y_pred\n",
    "                    \n",
    "                    \n",
    "            try:\n",
    "                self.X_stack_train = np.r_[self.X_stack_train, X_stack_train_fold]\n",
    "            except ValueError:\n",
    "                self.X_stack_train = X_stack_train_fold\n",
    "                \n",
    "                \n",
    "            self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "            \n",
    "            self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.classifiers_ = list()\n",
    "            for i in range(0, self.base_estimator_duplicates):\n",
    "                for t in self.base_estimator_types:\n",
    "\n",
    "                    self.base_estimator_type_list.append(t)      \n",
    "                    c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
    "                    X_samp, y_samp = resample(X, y, replace=True)\n",
    "                    c.fit(X_samp, y_samp )\n",
    "                    self.classifiers_.append(c)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "        X = check_array(X)\n",
    "        X_stack_queries = None\n",
    "        \n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "            \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "                \n",
    "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, n_labels].\n",
    "            The predicted class label probabilities of the input samples. \n",
    "        \"\"\"\n",
    "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
    "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
    "\n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "        \n",
    "        X_stack_queries = None\n",
    "        \n",
    "        # Make a prediction with each base classifier\n",
    "        for classifier in self.classifiers_:\n",
    "            \n",
    "            y_pred = classifier.predict_proba(X)\n",
    "                \n",
    "            try:\n",
    "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
    "            except ValueError:\n",
    "                X_stack_queries = y_pred\n",
    "\n",
    "        # Return the prediction made by the stack layer classifier        \n",
    "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                \n",
    "                \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [51, 102]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-11a1bee87bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedEnsembleClassifierKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-8fee61991676>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_layer_classifier_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_layer_classifier_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_min_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_layer_classifier_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_stack_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_stack_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1216\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [51, 102]"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "clf = StackedEnsembleClassifierKFold()\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of Different Stack Layer Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Comparing the Performance of Different Stack Layer Approaches with  More Standard Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Implement the StackedEnsembleOneVsOne Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 Evaluate the Performance of the StackedEnsembleCalassifierOneVsOne Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your reflection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
